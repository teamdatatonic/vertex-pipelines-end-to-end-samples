{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# MLOps Hackathon\n",
    "\n",
    "This hackathon is based on the [open-source Turbo Template](https://github.com/teamdatatonic/vertex-pipelines-end-to-end-samples).\n",
    "Through this notebook series you'll get hands-on with the template and Google Cloud.\n",
    "The hackathon is structured into the following exercises:\n",
    "\n",
    "1. [Health check](./01_health_check.ipynb)\n",
    "1. **[Run pipelines](./02_run_pipelines.ipynb) - this notebook**\n",
    "1. [Promote model](./03_promote_model.ipynb)\n",
    "1. [Challenge: Model monitoring](./04_monitoring_challenge.ipynb)\n",
    "1. [Challenge: Real-time predictions](./05_realtime_challenge.ipynb)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook you'll run your first training and prediction pipelines. \n",
    "You'll learn about containers, pipelines, caching, and `make` as a productivity accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate\n",
    "\n",
    "Set your project ID and authenticate using your Google Account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTEX_PROJECT_ID = \"my-project-id\"\n",
    "GOOGLE_ACCOUNT = \"user@company.com\"\n",
    "! gcloud config set project {VERTEX_PROJECT_ID}\n",
    "! gcloud config set account {GOOGLE_ACCOUNT}\n",
    "! gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running any pipelines, make sure you have created a `env.sh` and replaced the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Pipeline\n",
    "\n",
    "Vertex AI Pipelines uses KubeFlow to orchestrate your training steps, as such you'll need to:\n",
    "\n",
    "1. Compile the pipeline\n",
    "1. Build dependent Docker containers\n",
    "1. Run the pipeline in Vertex AI\n",
    "\n",
    "The already templated training pipeline will execute a pipeline similar to the image below in Vertex AI:\n",
    "\n",
    "![Training Pipeline](../docs/images/training_pipeline.png)\n",
    "\n",
    "Don't worry about executing steps 1-3 manually (and each time you run your pipeline!), simply run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! make training wait=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the pipeline executes, here's a more detailed explanation of what's happening:\n",
    "\n",
    "**1. Compile the pipeline:** By using the KubeFlow SDK, you've compiled the training pipeline in `pipelines/training` to YAML.\n",
    "\n",
    "**2. Build dependent Docker containers:** In `model` you can maintain your training (and prediction) code which is containerised and pushed to [Artifact Registry](https://cloud.google.com/artifact-registry). \n",
    "In this way, your training pipeline can execute your training code in the `Train model` pipeline step.\n",
    "\n",
    "**3. Run the pipeline in Vertex AI:** By using the Vertex AI Python SDK and the pipeline YAML file, you execute your training pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è Exercise:** With the help of `make help`, try to execute the steps 1-3 individually.\n",
    "\n",
    "**‚û°Ô∏è Exercise:** Have you noticed the caching option? What happens if you run the pipeline with cachine enabled vs. disabled. Why is one option preferred over the other?\n",
    "\n",
    "**‚û°Ô∏è Exercise:** Locate the model training code. Then:\n",
    "1. Update the training code (e.g. add a logging command).\n",
    "2. Rebuild the container using `make`\n",
    "3. Run the training pipeline with caching enabled. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Prediction Pipeline\n",
    "\n",
    "After running a successful training pipeline job, run the prediction pipeline which will look similar to:\n",
    "\n",
    "<img src=\"../docs/images/prediction_pipeline.png\" alt=\"image\" width=\"500\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** The command has the following true/false flags:\n",
    "\n",
    "- `build` - re-build containers for training & prediction code (limit by setting `images=training` to build only one of the containers)\n",
    "- `compile` - re-compile the pipeline to YAML\n",
    "- `wait` - run the pipeline (a-)sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è Exercise:** Can you locate the batch prediction job in Vertex AI? What are the inputs and outputs of the job?\n",
    "\n",
    "## Monitoring\n",
    "\n",
    "**‚û°Ô∏è Exercise:** Do you notice any monitoring as part of the batch prediction job? What is monitored? Are the any alerts?\n",
    "\n",
    "**‚û°Ô∏è Exercise:** Where in the code can you configure to receive email notifications in case of any alerts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your understanding\n",
    "\n",
    "**‚û°Ô∏è Exercise:** Understanding of containers:\n",
    "- Why do we need 2x containers?\n",
    "- When are they built?\n",
    "- In which cases do you need to rebuild a container, when can you skip it?\n",
    "- Can you locate the containers in the Google Cloud console?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You've successfully run your first training and prediction pipeline in Vertex AI! üéâ Now you're ready for the next exercise!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb5c7b0035bb37e2e2e56e6840dfdd8f7fa070884ae8e041fbcae450545b1006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
